# server configs for https://huggingface.co/RedHatAI/Meta-Llama-3.1-8B-Instruct-quantized.w4a16
model: "RedHatAI/Meta-Llama-3.1-8B-Instruct-quantized.w4a16"
trust-remote-code: true
enable-chunked-prefill: true
tensor-parallel-size:
max-model-len: 4096
