# from gs://nm-vllm-certs/model-validation/lmeval/mistralai/Mistral-Small-3.1-24B-Instruct-2503/cuda/0.8.4.post1/ibm02-a100-octo/llm_eval_0.json
tasks:
  - name: arc_challenge
    metrics:
      - name: acc_norm,none
        value: 0.715

  - name: gsm8k
    metrics:
      - name: exact_match,strict-match
        value: 0.89

  - name: hellaswag
    metrics:
      - name: acc_norm,none
        value: 0.8573

  - name: mmlu
    metrics:
      - name: acc,none
        value: 0.8109

  - name: truthfulqa_mc2
    metrics:
      - name: acc,none
        value: 0.6409

  - name: winogrande
    metrics:
      - name: acc,none
        value: 0.8374

  - name: leaderboard_ifeval
    metrics:
      - name: inst_level_strict_acc,none
        value: 0.729

  # - name: leaderboard_bbh
  #   metrics:
  #     - name: acc-norm,none
  #       value: 0.5319

  # - name: leaderboard_math_hard
  #   metrics:
  #     - name: exact_match,none
  #       value: 0.1477

  # - name: leaderboard_gpqa
  #   metrics:
  #     - name: acc-norm,none
  #       value: 0.3176

  # - name: leaderboard_musr
  #   metrics:
  #     - name: acc-norm,none
  #       value: 0.4601

  - name: leaderboard_mmlu_pro
    metrics:
      - name: acc,none
        value: 0.5545
  